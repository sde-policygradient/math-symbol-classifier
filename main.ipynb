{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Eudq1Z1EM0x"
   },
   "source": [
    "\n",
    "# Contents\n",
    "\n",
    "0. Setup\n",
    "1. Acquisition of Data\n",
    "2. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYKoNVrVC2-B"
   },
   "source": [
    "\n",
    "# Section 0: Setup\n",
    "\n",
    "## Prerequisites are essential by definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bHJYzqJ4xOfY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 17:01:49.937675: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750068110.154554    1272 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750068110.205181    1272 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750068110.644748    1272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750068110.644782    1272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750068110.644784    1272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750068110.644786    1272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-16 17:01:50.692055: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import mlcroissant as mlc\n",
    "import contextlib\n",
    "import zipfile, rarfile, tarfile\n",
    "import re\n",
    "import pickle\n",
    "import kagglehub\n",
    "import io\n",
    "from PIL import Image\n",
    "from typing import Any, Callable, Generator\n",
    "from IPython.display import display, clear_output\n",
    "import secrets\n",
    "import ipywidgets as widgets\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".cell-output-ipywidget-background{\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".jp-OutputArea-output{\n",
       "    background-color: transparent;\n",
       "    color: white;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<style>\n",
    ".cell-output-ipywidget-background{\n",
    "    background-color: transparent !important;\n",
    "}\n",
    "\n",
    ".jp-OutputArea-output{\n",
    "    background-color: transparent;\n",
    "    color: white;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "am0R-IYGyRjf"
   },
   "outputs": [],
   "source": [
    "dataset_url: str = \"https://www.kaggle.com/datasets/xainano/handwrittenmathsymbols\"\n",
    "\n",
    "jsonld_path: pathlib.Path = pathlib.Path(\"./croissants/handwrittenmathsymbols-metadata.json\")\n",
    "dataset_data_archive_path: pathlib.Path = pathlib.Path(\"./data.rar\")\n",
    "image_dict_pickle_path: pathlib.Path = pathlib.Path(\"./pickles/image_dict.pkl\")\n",
    "model_path: pathlib.Path = pathlib.Path(\"./keras_models/model.keras\")\n",
    "\n",
    "load_image_dict: bool = True\n",
    "load_model: bool = True\n",
    "\n",
    "image_display_resize: tuple[int, int] = (200, 200)\n",
    "image_display_resampling: int = Image.Resampling.BICUBIC\n",
    "dataset_image_resize: tuple[int, int] = (45, 45)\n",
    "dataset_image_resampling: str = tf.image.ResizeMethod.BICUBIC\n",
    "\n",
    "dataset_shuffle_buffer_size: int | None = 10000\n",
    "train_split: float = 0.8\n",
    "dataset_batch_size: int = 64\n",
    "\n",
    "model_init_hidden_layers: list[layers.Layer] = [\n",
    "    layers.Conv2D(64, 3, activation = \"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, activation = \"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(48, 3, activation = \"relu\"),\n",
    "    layers.SpatialDropout2D(0.2),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(48, activation = \"relu\"),\n",
    "    layers.Dense(32, activation = \"relu\"),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(16, activation = \"relu\")\n",
    "]\n",
    "\n",
    "train_epochs: int = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4O7DpVeCBtx"
   },
   "source": [
    "\n",
    "# Section 1: Acquisition of Data\n",
    "\n",
    "## The very foundation of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "C2SqQUXwnU3P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:WARNING: The JSON-LD `@context` is not standard. Refer to the official @context (e.g., from the example datasets in https://github.com/mlcommons/croissant/tree/main/datasets/1.0). The different keys are: {'citeAs', 'rai', 'isLiveDataset', 'examples'}\n",
      "WARNING:absl:Found the following 1 warning(s) during the validation:\n",
      "  -  [Metadata(Handwritten math symbols dataset)] Property \"http://mlcommons.org/croissant/citeAs\" is recommended, but does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[2J\u001b[93;1mDataset at https://www.kaggle.com/datasets/xainano/handwrittenmathsymbols\u001b[0m\n",
      "\n",
      "Handwritten math symbols dataset\n",
      "Published: 2017-01-15 16:49:28.723000\n"
     ]
    }
   ],
   "source": [
    "metadata: mlc.Metadata = mlc.Dataset(jsonld = jsonld_path).metadata\n",
    "\n",
    "print(f\"\\n\\n\\n\\x1b[2J\\x1b[93;1mDataset at {dataset_url}\\x1b[0m\\n\\n{metadata.name}\\nPublished: {metadata.date_published}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "a8S9xMPrskzA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from pickle\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "image_dict: dict[str, list[bytes]] = {}\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def open_archive(path: pathlib.Path) -> Generator[zipfile.ZipFile | rarfile.RarFile | tarfile.TarFile, None, None]:\n",
    "    if not path.is_file():\n",
    "        raise FileNotFoundError(f\"File not found\")\n",
    "\n",
    "    file: zipfile.ZipFile | rarfile.RarFile | tarfile.TarFile | None = None\n",
    "\n",
    "    match path.suffix:\n",
    "        case \".zip\":\n",
    "            file =  zipfile.ZipFile(path)\n",
    "        case \".rar\":\n",
    "            file =  rarfile.RarFile(path)\n",
    "        case suffix if re.search(suffix, r\"\\.tar(\\.[^ \\n]+)?\"):\n",
    "            file = tarfile.open(path)\n",
    "        case _:\n",
    "            raise ValueError(\"File type not supported\")\n",
    "    try:\n",
    "        yield file\n",
    "    finally:\n",
    "        if file is not None:\n",
    "            file.close()\n",
    "\n",
    "def archive_type_switch(archive_file: zipfile.ZipFile | rarfile.RarFile | tarfile.TarFile, input: tuple[Any, ...], zip_or_rar_callback: Callable[..., Any], tar_callback: Callable[[Any], Any]) -> Any:\n",
    "    match type(archive_file):\n",
    "        case zipfile.ZipFile | rarfile.RarFile:\n",
    "            return zip_or_rar_callback(*input)\n",
    "        case tarfile.TarFile:\n",
    "            return tar_callback(*input)\n",
    "\n",
    "def dict_get_data_archive(image_dict: dict[str, list[bytes]], path: pathlib.Path) -> None:\n",
    "    with open_archive(path) as archive_file:\n",
    "        for entry in archive_type_switch(archive_file, (archive_file, ), lambda x: x.infolist(), lambda x: x.get_members()):\n",
    "            if archive_type_switch(archive_file, (entry, ), lambda x: x.is_dir(), lambda x: x.isdir()):\n",
    "                continue\n",
    "\n",
    "            with archive_file.open(entry, \"r\") as image_file:\n",
    "                entry_label: str = entry.filename.split('/')[-2]\n",
    "\n",
    "                image_dict.setdefault(entry_label, []).append(archive_type_switch(archive_file, (archive_file, ), lambda x: x.read(), lambda x: x.extractfile()))\n",
    "                print(f\"Added {entry.filename} with label {entry_label}\")\n",
    "\n",
    "try:\n",
    "    assert load_image_dict\n",
    "\n",
    "    with open(image_dict_pickle_path, \"rb\") as pickle_file:\n",
    "        print(\"Loading from pickle\")\n",
    "        image_dict = pickle.load(pickle_file)\n",
    "except Exception:\n",
    "    with open(image_dict_pickle_path, \"wb\") as pickle_file:\n",
    "        print(\"Downloading dataset\")\n",
    "        dataset_path: pathlib.Path = pathlib.Path(kagglehub.dataset_download(dataset_url[dataset_url.rfind(\"datasets\") + len(\"datasets\") + 1:]))\n",
    "        print(\"Fetching from dataset\")\n",
    "        dict_get_data_archive(image_dict, dataset_path.joinpath(dataset_data_archive_path))\n",
    "        pickle.dump(image_dict, pickle_file)\n",
    "\n",
    "del open_archive, archive_type_switch, dict_get_data_archive\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fmvo8W3ZiUXP"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979ec6a1e1ea460ebbe62247d797c464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199cd27c825d4dbfb1b377202397d9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Next Image', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image_n_label(output: widgets.Output, image_dict: dict[str, list[bytes]], image_display_size: tuple[int, int], resampling: int) -> None:\n",
    "    with output:\n",
    "        random_label: str = secrets.choice(list(image_dict.keys()))\n",
    "        image_bytes: bytes = secrets.choice(image_dict[random_label])\n",
    "\n",
    "        clear_output(wait = True)\n",
    "        display(Image.open(io.BytesIO(image_bytes)).resize(image_display_size, resampling))\n",
    "        print(f\"Label: {random_label}\")\n",
    "\n",
    "image_display_size: tuple[int, int] = (200, 200)\n",
    "output: widgets.Output = widgets.Output()\n",
    "next_button: widgets.Button = widgets.Button(description = \"Next Image\")\n",
    "\n",
    "next_button.on_click(lambda button: show_image_n_label(output, image_dict, image_display_size, image_display_resampling))\n",
    "next_button.click()\n",
    "display(output)\n",
    "display(next_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ntU78G8IcjsJ"
   },
   "outputs": [],
   "source": [
    "def dataset_generator(image_dict: dict[str, list[bytes]], label_lookup: layers.StringLookup) -> Generator[tuple[bytes, tf.Tensor], None, None]:\n",
    "    for key in image_dict.keys():\n",
    "        for image_bytes in image_dict[key]:\n",
    "            yield image_bytes, tf.squeeze(label_lookup(key))\n",
    "\n",
    "def preprocess_image_bytes(image_bytes: bytes) -> tf.Tensor:\n",
    "    image: tf.Tensor = tf.io.decode_image(image_bytes, channels = 3)\n",
    "\n",
    "    image.set_shape([None, None, 3])\n",
    "    image = tf.image.resize_with_pad(image, dataset_image_resize[0], dataset_image_resize[1], dataset_image_resampling)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image\n",
    "\n",
    "image_dict_key_list: list[str] = list(image_dict.keys())\n",
    "image_size: tuple[int, int] = Image.open(io.BytesIO(list(image_dict.values())[0][0])).size\n",
    "\n",
    "output_signature: tuple[tf.TensorSpec] = (\n",
    "    tf.TensorSpec(shape = (), dtype = tf.string),\n",
    "    tf.TensorSpec(shape = (len(image_dict_key_list) + 1, ), dtype = tf.int32)\n",
    ")\n",
    "\n",
    "label_lookup: layers.StringLookup = layers.StringLookup(vocabulary = image_dict_key_list, output_mode = \"one_hot\")\n",
    "dataset: tf.data.Dataset = tf.data.Dataset.from_generator(lambda: dataset_generator(image_dict, label_lookup), output_signature = output_signature)\n",
    "\n",
    "dataset = dataset.map(lambda x, y: (preprocess_image_bytes(x), y), num_parallel_calls = tf.data.AUTOTUNE, deterministic = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "aK2puKOam3xf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted 375974 total elements\n",
      "Training set: 300779\n",
      "Validation set: 75195\n"
     ]
    }
   ],
   "source": [
    "def get_dataset_length(image_dict: dict[str, list[bytes]]) -> int:\n",
    "    total_length: int = 0\n",
    "\n",
    "    for value in image_dict.values():\n",
    "        total_length += len(value)\n",
    "\n",
    "    return total_length\n",
    "\n",
    "dataset_count: int = get_dataset_length(image_dict)\n",
    "\n",
    "dataset = dataset.shuffle(dataset_count if dataset_shuffle_buffer_size is None else dataset_shuffle_buffer_size)\n",
    "\n",
    "train_elements: int = int(dataset_count * train_split)\n",
    "train_dataset: tf.data.Dataset = dataset.take(train_elements)\n",
    "val_dataset: tf.data.Dataset = dataset.skip(train_elements)\n",
    "\n",
    "print(f\"Counted {dataset_count} total elements\\nTraining set: {train_elements}\\nValidation set: {dataset_count - train_elements}\")\n",
    "\n",
    "train_dataset = train_dataset.batch(dataset_batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(dataset_batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwDB3cwSaSLt"
   },
   "source": [
    "\n",
    "# Section 2: Model Building\n",
    "\n",
    "## What is Image Classification without an Image Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rQcvGwfuzz-5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 18:48:54.659712: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:38: Filling up shuffle buffer (this may take a while): 4370 of 10000\n",
      "2025-06-16 18:49:07.076356: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4699/Unknown \u001b[1m741s\u001b[0m 152ms/step - accuracy: 0.6130 - loss: 1.3612"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 19:01:04.764505: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.9 = (f32[43,64,43,43]{3,2,1,0}, u8[0]{0}) custom-call(f32[43,3,45,45]{3,2,1,0} %bitcast.7662, f32[64,3,3,3]{3,2,1,0} %bitcast.7669, f32[64]{0} %bitcast.8282), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1_1/conv2d_1/convolution\" source_file=\"/home/tebapunix/math-symbol-classifier/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-16 19:01:04.795149: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.10 = (f32[43,64,19,19]{3,2,1,0}, u8[0]{0}) custom-call(f32[43,64,21,21]{3,2,1,0} %bitcast.8346, f32[64,64,3,3]{3,2,1,0} %bitcast.7689, f32[64]{0} %bitcast.8406), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1_1/conv2d_1_2/convolution\" source_file=\"/home/tebapunix/math-symbol-classifier/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-16 19:01:04.899793: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[43,48,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[43,64,9,9]{3,2,1,0} %bitcast.8469, f32[48,64,3,3]{3,2,1,0} %bitcast.7708, f32[48]{0} %bitcast.8529), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1_1/conv2d_2_1/convolution\" source_file=\"/home/tebapunix/math-symbol-classifier/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4700/Unknown \u001b[1m744s\u001b[0m 153ms/step - accuracy: 0.6130 - loss: 1.3612"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 19:01:17.710174: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:38: Filling up shuffle buffer (this may take a while): 4617 of 10000\n",
      "2025-06-16 19:01:27.710543: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:38: Filling up shuffle buffer (this may take a while): 9125 of 10000\n",
      "2025-06-16 19:01:29.687193: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n",
      "2025-06-16 19:12:29.465948: E external/local_xla/xla/stream_executor/cuda/cuda_timer.cc:86] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2025-06-16 19:12:29.517304: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.9 = (f32[64,64,43,43]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,3,45,45]{3,2,1,0} %bitcast.609, f32[64,3,3,3]{3,2,1,0} %bitcast.616, f32[64]{0} %bitcast.618), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1_1/conv2d_1/convolution\" source_file=\"/home/tebapunix/math-symbol-classifier/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-16 19:12:29.554428: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.10 = (f32[64,64,19,19]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,64,21,21]{3,2,1,0} %bitcast.625, f32[64,64,3,3]{3,2,1,0} %bitcast.632, f32[64]{0} %bitcast.634), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1_1/conv2d_1_2/convolution\" source_file=\"/home/tebapunix/math-symbol-classifier/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-16 19:12:29.634245: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[64,48,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,64,9,9]{3,2,1,0} %bitcast.640, f32[48,64,3,3]{3,2,1,0} %bitcast.647, f32[48]{0} %bitcast.649), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1_1/conv2d_2_1/convolution\" source_file=\"/home/tebapunix/math-symbol-classifier/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-16 19:14:55.600074: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.9 = (f32[59,64,43,43]{3,2,1,0}, u8[0]{0}) custom-call(f32[59,3,45,45]{3,2,1,0} %bitcast.609, f32[64,3,3,3]{3,2,1,0} %bitcast.616, f32[64]{0} %bitcast.618), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1_1/conv2d_1/convolution\" source_file=\"/home/tebapunix/math-symbol-classifier/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-16 19:14:55.631418: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.10 = (f32[59,64,19,19]{3,2,1,0}, u8[0]{0}) custom-call(f32[59,64,21,21]{3,2,1,0} %bitcast.625, f32[64,64,3,3]{3,2,1,0} %bitcast.632, f32[64]{0} %bitcast.634), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1_1/conv2d_1_2/convolution\" source_file=\"/home/tebapunix/math-symbol-classifier/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-16 19:14:55.722758: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[59,48,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[59,64,9,9]{3,2,1,0} %bitcast.640, f32[48,64,3,3]{3,2,1,0} %bitcast.647, f32[48]{0} %bitcast.649), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1_1/conv2d_2_1/convolution\" source_file=\"/home/tebapunix/math-symbol-classifier/.venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4700/4700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1573s\u001b[0m 329ms/step - accuracy: 0.6130 - loss: 1.3611 - val_accuracy: 0.0077 - val_loss: 10.7376\n",
      "Epoch 2/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 19:14:56.316317: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2025-06-16 19:14:56.316396: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 3763693996949390649\n",
      "2025-06-16 19:14:56.316452: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 3372084804896467218\n",
      "2025-06-16 19:15:06.426739: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:38: Filling up shuffle buffer (this may take a while): 4573 of 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/4700\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:39:02\u001b[0m 22s/step - accuracy: 0.0000e+00 - loss: 3.8405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 19:15:18.208168: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4700/4700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.7953 - loss: 0.6630"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 19:27:15.510855: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:38: Filling up shuffle buffer (this may take a while): 4633 of 10000\n",
      "2025-06-16 19:27:25.512787: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:38: Filling up shuffle buffer (this may take a while): 9238 of 10000\n",
      "2025-06-16 19:27:27.186050: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4700/4700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1551s\u001b[0m 325ms/step - accuracy: 0.7953 - loss: 0.6631 - val_accuracy: 0.0099 - val_loss: 12.7220\n",
      "Epoch 3/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 19:40:47.284554: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 3763693996949390649\n",
      "2025-06-16 19:40:47.284622: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 3372084804896467218\n",
      "2025-06-16 19:40:57.304633: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:38: Filling up shuffle buffer (this may take a while): 4556 of 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/4700\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:27:05\u001b[0m 22s/step - accuracy: 0.0000e+00 - loss: 3.8967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 19:41:08.944981: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4700/4700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8423 - loss: 0.5209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 19:53:09.734318: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:38: Filling up shuffle buffer (this may take a while): 4508 of 10000\n",
      "2025-06-16 19:53:21.704048: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4700/4700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1584s\u001b[0m 332ms/step - accuracy: 0.8423 - loss: 0.5210 - val_accuracy: 0.0318 - val_loss: 16.6940\n",
      "Epoch 4/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 20:07:10.871766: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 3763693996949390649\n",
      "2025-06-16 20:07:10.871843: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 3372084804896467218\n",
      "2025-06-16 20:07:20.898855: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:38: Filling up shuffle buffer (this may take a while): 4604 of 10000\n",
      "2025-06-16 20:07:30.899200: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:38: Filling up shuffle buffer (this may take a while): 9161 of 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/4700\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:42:49\u001b[0m 22s/step - accuracy: 0.0000e+00 - loss: 4.4214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 20:07:32.742507: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4700/4700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8536 - loss: 0.7393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 20:19:51.431843: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:38: Filling up shuffle buffer (this may take a while): 4545 of 10000\n",
      "2025-06-16 20:20:03.635671: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4700/4700\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1623s\u001b[0m 341ms/step - accuracy: 0.8536 - loss: 0.7395 - val_accuracy: 0.0268 - val_loss: 15.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 20:34:14.015223: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 3763693996949390649\n",
      "2025-06-16 20:34:14.015313: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 3372084804896467218\n"
     ]
    }
   ],
   "source": [
    "def init_image_classifier(input_shape: tuple[int, ...], hidden_layers: list[layers.Layer], output_shape: int) -> keras.Sequential:\n",
    "    model: keras.Sequential = keras.Sequential()\n",
    "\n",
    "    model.add(layers.Input(input_shape))\n",
    "\n",
    "    for layer in hidden_layers:\n",
    "        model.add(layer)\n",
    "\n",
    "    model.add(layers.Dense(output_shape, activation = \"softmax\"))\n",
    "    return model\n",
    "\n",
    "try:\n",
    "    assert load_model\n",
    "\n",
    "    model: keras.Sequential = keras.models.load_model(model_path)\n",
    "except:\n",
    "    model: keras.Sequential = init_image_classifier((image_size[0], image_size[1], 3), model_init_hidden_layers, len(image_dict_key_list) + 1)\n",
    "\n",
    "    model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "finally:\n",
    "    early_stop_callback: keras.callbacks.EarlyStopping = keras.callbacks.EarlyStopping(\n",
    "        patience = 3,\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "\n",
    "    checkpoint_callback: keras.callbacks.ModelCheckpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath = model_path,\n",
    "        save_best_only = True\n",
    "    )\n",
    "\n",
    "    model.fit(train_dataset, validation_data = val_dataset,epochs = train_epochs, callbacks = [early_stop_callback, checkpoint_callback], verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNTdO4pTcYFqX2JySokdoMF",
   "mount_file_id": "1ns6x2as7eTq1NhYpFr_BBMQIg3pddl4y",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
