{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Eudq1Z1EM0x"
   },
   "source": [
    "\n",
    "# Contents\n",
    "\n",
    "0. Setup\n",
    "1. Acquisition of Data\n",
    "2. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYKoNVrVC2-B"
   },
   "source": [
    "\n",
    "# Section 0: Setup\n",
    "\n",
    "## Prerequisites are essential by definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bHJYzqJ4xOfY"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import mlcroissant as mlc\n",
    "import contextlib\n",
    "import zipfile, rarfile, tarfile\n",
    "import re\n",
    "import pickle\n",
    "import kagglehub\n",
    "import io\n",
    "from PIL import Image\n",
    "from typing import Any, Callable, Generator\n",
    "from IPython.display import display, clear_output\n",
    "import secrets\n",
    "import ipywidgets as widgets\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".cell-output-ipywidget-background{\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".jp-OutputArea-output{\n",
       "    background-color: transparent;\n",
       "    color: white;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<style>\n",
    ".cell-output-ipywidget-background{\n",
    "    background-color: transparent !important;\n",
    "}\n",
    "\n",
    ".jp-OutputArea-output{\n",
    "    background-color: transparent;\n",
    "    color: white;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "am0R-IYGyRjf"
   },
   "outputs": [],
   "source": [
    "dataset_url: str = \"https://www.kaggle.com/datasets/xainano/handwrittenmathsymbols\"\n",
    "\n",
    "jsonld_path: pathlib.Path = pathlib.Path(\"./croissants/handwrittenmathsymbols-metadata.json\")\n",
    "dataset_data_archive_path: pathlib.Path = pathlib.Path(\"./data.rar\")\n",
    "image_dict_pickle_path: pathlib.Path = pathlib.Path(\"./pickles/image_dict.pkl\")\n",
    "model_path: pathlib.Path = pathlib.Path(\"./keras_models/model.keras\")\n",
    "\n",
    "load_image_dict: bool = True\n",
    "load_model: bool = True\n",
    "\n",
    "image_display_resize: tuple[int, int] = (200, 200)\n",
    "image_display_resampling: int = Image.Resampling.BICUBIC\n",
    "dataset_image_resize: tuple[int, int] = (45, 45)\n",
    "dataset_image_resampling: str = tf.image.ResizeMethod.BICUBIC\n",
    "\n",
    "dataset_generator_shards: int = 4\n",
    "dataset_shuffle_buffer_size: int | None = 10000\n",
    "train_split: float = 0.8\n",
    "dataset_batch_size: int = 32\n",
    "\n",
    "model_init_hidden_layers: list[layers.Layer] = [\n",
    "    layers.Conv2D(64, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(64, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.SpatialDropout2D(0.1),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.SpatialDropout2D(0.1),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(256, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(256, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(256, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.SpatialDropout2D(0.2),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(512, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(512, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(512, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.SpatialDropout2D(0.3),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(4096, activation = \"relu\"),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(4096, activation = \"relu\")\n",
    "]\n",
    "\n",
    "early_stopping_patience: int = 3\n",
    "train_epochs: int = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4O7DpVeCBtx"
   },
   "source": [
    "\n",
    "# Section 1: Acquisition of Data\n",
    "\n",
    "## The very foundation of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "C2SqQUXwnU3P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:WARNING: The JSON-LD `@context` is not standard. Refer to the official @context (e.g., from the example datasets in https://github.com/mlcommons/croissant/tree/main/datasets/1.0). The different keys are: {'examples', 'citeAs', 'rai', 'isLiveDataset'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found the following 1 warning(s) during the validation:\n",
      "  -  [Metadata(Handwritten math symbols dataset)] Property \"http://mlcommons.org/croissant/citeAs\" is recommended, but does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[2J\u001b[93;1mDataset at https://www.kaggle.com/datasets/xainano/handwrittenmathsymbols\u001b[0m\n",
      "\n",
      "Handwritten math symbols dataset\n",
      "Published: 2017-01-15 16:49:28.723000\n"
     ]
    }
   ],
   "source": [
    "metadata: mlc.Metadata = mlc.Dataset(jsonld = jsonld_path).metadata\n",
    "\n",
    "print(f\"\\n\\n\\n\\x1b[2J\\x1b[93;1mDataset at {dataset_url}\\x1b[0m\\n\\n{metadata.name}\\nPublished: {metadata.date_published}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "a8S9xMPrskzA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from pickle\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "image_dict: dict[str, list[bytes]] = {}\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def open_archive(path: pathlib.Path) -> Generator[zipfile.ZipFile | rarfile.RarFile | tarfile.TarFile, None, None]:\n",
    "    if not path.is_file():\n",
    "        raise FileNotFoundError(f\"File not found\")\n",
    "\n",
    "    file: zipfile.ZipFile | rarfile.RarFile | tarfile.TarFile | None = None\n",
    "\n",
    "    match path.suffix:\n",
    "        case \".zip\":\n",
    "            file =  zipfile.ZipFile(path)\n",
    "        case \".rar\":\n",
    "            file =  rarfile.RarFile(path)\n",
    "        case suffix if re.search(suffix, r\"\\.tar(\\.[^ \\n]+)?\"):\n",
    "            file = tarfile.open(path)\n",
    "        case _:\n",
    "            raise ValueError(\"File type not supported\")\n",
    "    try:\n",
    "        yield file\n",
    "    finally:\n",
    "        if file is not None:\n",
    "            file.close()\n",
    "\n",
    "def archive_type_switch(archive_file: zipfile.ZipFile | rarfile.RarFile | tarfile.TarFile, input: tuple[Any, ...], zip_or_rar_callback: Callable[..., Any], tar_callback: Callable[[Any], Any]) -> Any:\n",
    "    match type(archive_file):\n",
    "        case zipfile.ZipFile | rarfile.RarFile:\n",
    "            return zip_or_rar_callback(*input)\n",
    "        case tarfile.TarFile:\n",
    "            return tar_callback(*input)\n",
    "\n",
    "def dict_get_data_archive(image_dict: dict[str, list[bytes]], path: pathlib.Path) -> None:\n",
    "    with open_archive(path) as archive_file:\n",
    "        for entry in archive_type_switch(archive_file, (archive_file, ), lambda x: x.infolist(), lambda x: x.get_members()):\n",
    "            if archive_type_switch(archive_file, (entry, ), lambda x: x.is_dir(), lambda x: x.isdir()):\n",
    "                continue\n",
    "\n",
    "            with archive_file.open(entry, \"r\") as image_file:\n",
    "                entry_label: str = entry.filename.split('/')[-2]\n",
    "\n",
    "                image_dict.setdefault(entry_label, []).append(archive_type_switch(archive_file, (archive_file, ), lambda x: x.read(), lambda x: x.extractfile()))\n",
    "                print(f\"Added {entry.filename} with label {entry_label}\")\n",
    "\n",
    "try:\n",
    "    assert load_image_dict\n",
    "\n",
    "    with open(image_dict_pickle_path, \"rb\") as pickle_file:\n",
    "        print(\"Loading from pickle\")\n",
    "        image_dict = pickle.load(pickle_file)\n",
    "except Exception:\n",
    "    with open(image_dict_pickle_path, \"wb\") as pickle_file:\n",
    "        print(\"Downloading dataset\")\n",
    "        dataset_path: pathlib.Path = pathlib.Path(kagglehub.dataset_download(dataset_url[dataset_url.rfind(\"datasets\") + len(\"datasets\") + 1:]))\n",
    "        print(\"Fetching from dataset\")\n",
    "        dict_get_data_archive(image_dict, dataset_path.joinpath(dataset_data_archive_path))\n",
    "        pickle.dump(image_dict, pickle_file)\n",
    "\n",
    "del open_archive, archive_type_switch, dict_get_data_archive\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Fmvo8W3ZiUXP"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f84d9195902417bb7e4a0bc1e4acb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2581220e666142e884b76b775e43f823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Next Image', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_image_n_label(output: widgets.Output, image_dict: dict[str, list[bytes]], image_display_size: tuple[int, int], resampling: int) -> None:\n",
    "    with output:\n",
    "        random_label: str = secrets.choice(list(image_dict.keys()))\n",
    "        image_bytes: bytes = secrets.choice(image_dict[random_label])\n",
    "\n",
    "        clear_output(wait = True)\n",
    "        display(Image.open(io.BytesIO(image_bytes)).resize(image_display_size, resampling))\n",
    "        print(f\"Label: {random_label}\")\n",
    "\n",
    "image_display_size: tuple[int, int] = (200, 200)\n",
    "output: widgets.Output = widgets.Output()\n",
    "next_button: widgets.Button = widgets.Button(description = \"Next Image\")\n",
    "\n",
    "next_button.on_click(lambda button: show_image_n_label(output, image_dict, image_display_size, image_display_resampling))\n",
    "next_button.click()\n",
    "display(output)\n",
    "display(next_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ntU78G8IcjsJ"
   },
   "outputs": [],
   "source": [
    "def get_shard_keys(num_shards: int, shard_index: int, image_dict: dict[str, list[bytes]]) -> list[str]:\n",
    "    shard_keys: list[str] = []\n",
    "    num_keys: int = len(image_dict.keys())\n",
    "\n",
    "    for i in range(shard_index, num_keys, num_shards):\n",
    "        shard_keys.append(list(image_dict.keys())[i])\n",
    "\n",
    "    return shard_keys\n",
    "\n",
    "def sharded_generator_factory(num_shards: int, shard_index: int, image_dict: dict[str, list[bytes]], label_lookup: layers.StringLookup) -> Callable[[], Generator[tuple[bytes, tf.Tensor], None, None]]:\n",
    "    def shard_generator() -> Generator[tuple[bytes, tf.Tensor], None, None]:\n",
    "        for key in get_shard_keys(num_shards, shard_index, image_dict):\n",
    "            for image_bytes in image_dict[key]:\n",
    "                yield image_bytes, tf.squeeze(label_lookup(key))\n",
    "\n",
    "    return shard_generator\n",
    "\n",
    "def preprocess_image_bytes(image_bytes: bytes) -> tf.Tensor:\n",
    "    image: tf.Tensor = tf.io.decode_image(image_bytes, channels = 3)\n",
    "\n",
    "    image.set_shape([None, None, 3])\n",
    "    image = tf.image.resize_with_pad(image, dataset_image_resize[0], dataset_image_resize[1], dataset_image_resampling)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image\n",
    "\n",
    "image_dict_key_list: list[str] = list(image_dict.keys())\n",
    "image_size: tuple[int, int] = Image.open(io.BytesIO(list(image_dict.values())[0][0])).size\n",
    "\n",
    "output_signature: tuple[tf.TensorSpec] = (\n",
    "    tf.TensorSpec(shape = (), dtype = tf.string),\n",
    "    tf.TensorSpec(shape = (len(image_dict_key_list), ), dtype = tf.int32)\n",
    ")\n",
    "\n",
    "label_lookup: layers.StringLookup = layers.StringLookup(vocabulary = image_dict_key_list, num_oov_indices = 0, output_mode = \"one_hot\")\n",
    "\n",
    "sharded_datsets: list[tf.data.Dataset] = [\n",
    "    tf.data.Dataset.from_generator(\n",
    "        sharded_generator_factory(dataset_generator_shards, i, image_dict, label_lookup),\n",
    "        output_signature = output_signature\n",
    "    )\n",
    "    for i in range(dataset_generator_shards)\n",
    "]\n",
    "\n",
    "dataset: tf.data.Dataset = tf.data.Dataset.from_tensor_slices(sharded_datsets).interleave(\n",
    "    lambda x: x,\n",
    "    cycle_length = dataset_generator_shards,\n",
    "    num_parallel_calls = tf.data.AUTOTUNE,\n",
    "    deterministic = False\n",
    ")\n",
    "\n",
    "dataset = dataset.map(lambda x, y: (preprocess_image_bytes(x), y), num_parallel_calls = tf.data.AUTOTUNE, deterministic = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "aK2puKOam3xf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted 375974 total elements\n",
      "Training set: 300779\n",
      "Validation set: 75195\n"
     ]
    }
   ],
   "source": [
    "def get_dataset_length(image_dict: dict[str, list[bytes]]) -> int:\n",
    "    total_length: int = 0\n",
    "\n",
    "    for value in image_dict.values():\n",
    "        total_length += len(value)\n",
    "\n",
    "    return total_length\n",
    "\n",
    "dataset_count: int = get_dataset_length(image_dict)\n",
    "\n",
    "dataset = dataset.shuffle(dataset_count if dataset_shuffle_buffer_size is None else dataset_shuffle_buffer_size)\n",
    "\n",
    "train_elements: int = int(dataset_count * train_split)\n",
    "train_dataset: tf.data.Dataset = dataset.take(train_elements)\n",
    "val_dataset: tf.data.Dataset = dataset.skip(train_elements)\n",
    "\n",
    "print(f\"Counted {dataset_count} total elements\\nTraining set: {train_elements}\\nValidation set: {dataset_count - train_elements}\")\n",
    "\n",
    "train_dataset = train_dataset.batch(dataset_batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(dataset_batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwDB3cwSaSLt"
   },
   "source": [
    "\n",
    "# Section 2: Model Building\n",
    "\n",
    "## What is Image Classification without an Image Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQcvGwfuzz-5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiled new model\n",
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 17:11:47.617269: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:61: Filling up shuffle buffer (this may take a while): 2996 of 10000\n",
      "2025-06-23 17:12:07.612313: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:61: Filling up shuffle buffer (this may take a while): 9259 of 10000\n",
      "2025-06-23 17:12:10.000888: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     78/Unknown \u001b[1m57s\u001b[0m 162ms/step - accuracy: 0.0000e+00 - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 40\u001b[0m\n\u001b[1;32m     26\u001b[0m early_stopping_callback: keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m     27\u001b[0m     monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     patience \u001b[38;5;241m=\u001b[39m early_stopping_patience,\n\u001b[1;32m     29\u001b[0m     restore_best_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     30\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     33\u001b[0m checkpoint_callback: keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     34\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m model_path,\n\u001b[1;32m     35\u001b[0m     monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m     save_best_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m )\n\u001b[0;32m---> 40\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/math-symbol-classifier/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/math-symbol-classifier/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/math-symbol-classifier/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:221\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    218\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    219\u001b[0m ):\n\u001b[1;32m    220\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/math-symbol-classifier/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/math-symbol-classifier/.venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOptionalHasValue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def init_image_classifier(input_shape: tuple[int, ...], hidden_layers: list[layers.Layer], output_shape: int) -> keras.Sequential:\n",
    "    model: keras.Sequential = keras.Sequential()\n",
    "\n",
    "    model.add(layers.Input(input_shape))\n",
    "\n",
    "    for layer in hidden_layers:\n",
    "        model.add(layer)\n",
    "\n",
    "    model.add(layers.Dense(output_shape, activation = \"softmax\"))\n",
    "    return model\n",
    "\n",
    "try:\n",
    "    assert load_model\n",
    "\n",
    "    model: keras.Sequential = keras.models.load_model(model_path)\n",
    "    \n",
    "    print(f\"Loaded model from {str(model_path)}\")\n",
    "except:\n",
    "    model: keras.Sequential = init_image_classifier((image_size[0], image_size[1], 3), model_init_hidden_layers, len(image_dict_key_list))\n",
    "\n",
    "    model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    print(f\"Compiled new model\")\n",
    "finally:\n",
    "    early_stopping_callback: keras.callbacks.EarlyStopping = keras.callbacks.EarlyStopping(\n",
    "        monitor = \"val_loss\",\n",
    "        patience = early_stopping_patience,\n",
    "        restore_best_weights = True,\n",
    "        mode = \"min\"\n",
    "    )\n",
    "\n",
    "    checkpoint_callback: keras.callbacks.ModelCheckpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath = model_path,\n",
    "        monitor = \"val_loss\",\n",
    "        save_best_only = True,\n",
    "        mode = \"min\"\n",
    "    )\n",
    "\n",
    "    model.fit(train_dataset, validation_data = val_dataset,epochs = train_epochs, callbacks = [early_stopping_callback, checkpoint_callback], verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNTdO4pTcYFqX2JySokdoMF",
   "mount_file_id": "1ns6x2as7eTq1NhYpFr_BBMQIg3pddl4y",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
