{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Eudq1Z1EM0x"
   },
   "source": [
    "\n",
    "# Contents\n",
    "\n",
    "0. Setup\n",
    "1. Acquisition of Data\n",
    "2. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYKoNVrVC2-B"
   },
   "source": [
    "\n",
    "# Section 0: Setup\n",
    "\n",
    "## Prerequisites are essential by definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHJYzqJ4xOfY"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import mlcroissant as mlc\n",
    "import contextlib\n",
    "import zipfile, rarfile, tarfile\n",
    "import re\n",
    "import pickle\n",
    "import kagglehub\n",
    "import io\n",
    "from PIL import Image\n",
    "from typing import Any, Callable, Generator\n",
    "from IPython.display import display, clear_output\n",
    "import secrets\n",
    "import ipywidgets as widgets\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<style>\n",
    ".cell-output-ipywidget-background{\n",
    "    background-color: transparent !important;\n",
    "}\n",
    "\n",
    ".jp-OutputArea-output{\n",
    "    background-color: transparent;\n",
    "    color: white;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "am0R-IYGyRjf"
   },
   "outputs": [],
   "source": [
    "dataset_url: str = \"https://www.kaggle.com/datasets/xainano/handwrittenmathsymbols\"\n",
    "\n",
    "jsonld_path: pathlib.Path = pathlib.Path(\"./croissants/handwrittenmathsymbols-metadata.json\")\n",
    "dataset_data_archive_path: pathlib.Path = pathlib.Path(\"./data.rar\")\n",
    "image_dict_pickle_path: pathlib.Path = pathlib.Path(\"./pickles/image_dict.pkl\")\n",
    "model_path: pathlib.Path = pathlib.Path(\"./keras_models/model.keras\")\n",
    "\n",
    "load_image_dict: bool = True\n",
    "load_model: bool = True\n",
    "\n",
    "image_display_resize: tuple[int, int] = (200, 200)\n",
    "image_display_resampling: int = Image.Resampling.BICUBIC\n",
    "dataset_image_resize: tuple[int, int] = (45, 45)\n",
    "dataset_image_resampling: str = tf.image.ResizeMethod.BICUBIC\n",
    "\n",
    "dataset_shuffle_buffer_size: int | None = 10000\n",
    "train_split: float = 0.8\n",
    "dataset_batch_size: int = 32\n",
    "\n",
    "model_init_hidden_layers: list[layers.Layer] = [\n",
    "    layers.Conv2D(64, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(64, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(128, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(256, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(256, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(256, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(512, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(512, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.Conv2D(512, 3, padding = \"same\", activation = \"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(4096, activation = \"relu\"),\n",
    "    layers.Dense(4096, activation = \"relu\")\n",
    "]\n",
    "\n",
    "train_epochs: int = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4O7DpVeCBtx"
   },
   "source": [
    "\n",
    "# Section 1: Acquisition of Data\n",
    "\n",
    "## The very foundation of analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2SqQUXwnU3P"
   },
   "outputs": [],
   "source": [
    "metadata: mlc.Metadata = mlc.Dataset(jsonld = jsonld_path).metadata\n",
    "\n",
    "print(f\"\\n\\n\\n\\x1b[2J\\x1b[93;1mDataset at {dataset_url}\\x1b[0m\\n\\n{metadata.name}\\nPublished: {metadata.date_published}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8S9xMPrskzA"
   },
   "outputs": [],
   "source": [
    "image_dict: dict[str, list[bytes]] = {}\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def open_archive(path: pathlib.Path) -> Generator[zipfile.ZipFile | rarfile.RarFile | tarfile.TarFile, None, None]:\n",
    "    if not path.is_file():\n",
    "        raise FileNotFoundError(f\"File not found\")\n",
    "\n",
    "    file: zipfile.ZipFile | rarfile.RarFile | tarfile.TarFile | None = None\n",
    "\n",
    "    match path.suffix:\n",
    "        case \".zip\":\n",
    "            file =  zipfile.ZipFile(path)\n",
    "        case \".rar\":\n",
    "            file =  rarfile.RarFile(path)\n",
    "        case suffix if re.search(suffix, r\"\\.tar(\\.[^ \\n]+)?\"):\n",
    "            file = tarfile.open(path)\n",
    "        case _:\n",
    "            raise ValueError(\"File type not supported\")\n",
    "    try:\n",
    "        yield file\n",
    "    finally:\n",
    "        if file is not None:\n",
    "            file.close()\n",
    "\n",
    "def archive_type_switch(archive_file: zipfile.ZipFile | rarfile.RarFile | tarfile.TarFile, input: tuple[Any, ...], zip_or_rar_callback: Callable[..., Any], tar_callback: Callable[[Any], Any]) -> Any:\n",
    "    match type(archive_file):\n",
    "        case zipfile.ZipFile | rarfile.RarFile:\n",
    "            return zip_or_rar_callback(*input)\n",
    "        case tarfile.TarFile:\n",
    "            return tar_callback(*input)\n",
    "\n",
    "def dict_get_data_archive(image_dict: dict[str, list[bytes]], path: pathlib.Path) -> None:\n",
    "    with open_archive(path) as archive_file:\n",
    "        for entry in archive_type_switch(archive_file, (archive_file, ), lambda x: x.infolist(), lambda x: x.get_members()):\n",
    "            if archive_type_switch(archive_file, (entry, ), lambda x: x.is_dir(), lambda x: x.isdir()):\n",
    "                continue\n",
    "\n",
    "            with archive_file.open(entry, \"r\") as image_file:\n",
    "                entry_label: str = entry.filename.split('/')[-2]\n",
    "\n",
    "                image_dict.setdefault(entry_label, []).append(archive_type_switch(archive_file, (archive_file, ), lambda x: x.read(), lambda x: x.extractfile()))\n",
    "                print(f\"Added {entry.filename} with label {entry_label}\")\n",
    "\n",
    "try:\n",
    "    assert load_image_dict\n",
    "\n",
    "    with open(image_dict_pickle_path, \"rb\") as pickle_file:\n",
    "        print(\"Loading from pickle\")\n",
    "        image_dict = pickle.load(pickle_file)\n",
    "except Exception:\n",
    "    with open(image_dict_pickle_path, \"wb\") as pickle_file:\n",
    "        print(\"Downloading dataset\")\n",
    "        dataset_path: pathlib.Path = pathlib.Path(kagglehub.dataset_download(dataset_url[dataset_url.rfind(\"datasets\") + len(\"datasets\") + 1:]))\n",
    "        print(\"Fetching from dataset\")\n",
    "        dict_get_data_archive(image_dict, dataset_path.joinpath(dataset_data_archive_path))\n",
    "        pickle.dump(image_dict, pickle_file)\n",
    "\n",
    "del open_archive, archive_type_switch, dict_get_data_archive\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fmvo8W3ZiUXP"
   },
   "outputs": [],
   "source": [
    "def show_image_n_label(output: widgets.Output, image_dict: dict[str, list[bytes]], image_display_size: tuple[int, int], resampling: int) -> None:\n",
    "    with output:\n",
    "        random_label: str = secrets.choice(list(image_dict.keys()))\n",
    "        image_bytes: bytes = secrets.choice(image_dict[random_label])\n",
    "\n",
    "        clear_output(wait = True)\n",
    "        display(Image.open(io.BytesIO(image_bytes)).resize(image_display_size, resampling))\n",
    "        print(f\"Label: {random_label}\")\n",
    "\n",
    "image_display_size: tuple[int, int] = (200, 200)\n",
    "output: widgets.Output = widgets.Output()\n",
    "next_button: widgets.Button = widgets.Button(description = \"Next Image\")\n",
    "\n",
    "next_button.on_click(lambda button: show_image_n_label(output, image_dict, image_display_size, image_display_resampling))\n",
    "next_button.click()\n",
    "display(output)\n",
    "display(next_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntU78G8IcjsJ"
   },
   "outputs": [],
   "source": [
    "def dataset_generator(image_dict: dict[str, list[bytes]], label_lookup: layers.StringLookup) -> Generator[tuple[bytes, tf.Tensor], None, None]:\n",
    "    for key in image_dict.keys():\n",
    "        for image_bytes in image_dict[key]:\n",
    "            yield image_bytes, tf.squeeze(label_lookup(key))\n",
    "\n",
    "def preprocess_image_bytes(image_bytes: bytes) -> tf.Tensor:\n",
    "    image: tf.Tensor = tf.io.decode_image(image_bytes, channels = 3)\n",
    "\n",
    "    image.set_shape([None, None, 3])\n",
    "    image = tf.image.resize_with_pad(image, dataset_image_resize[0], dataset_image_resize[1], dataset_image_resampling)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image\n",
    "\n",
    "image_dict_key_list: list[str] = list(image_dict.keys())\n",
    "image_size: tuple[int, int] = Image.open(io.BytesIO(list(image_dict.values())[0][0])).size\n",
    "\n",
    "output_signature: tuple[tf.TensorSpec] = (\n",
    "    tf.TensorSpec(shape = (), dtype = tf.string),\n",
    "    tf.TensorSpec(shape = (len(image_dict_key_list), ), dtype = tf.int32)\n",
    ")\n",
    "\n",
    "label_lookup: layers.StringLookup = layers.StringLookup(vocabulary = image_dict_key_list, num_oov_indices = 0, output_mode = \"one_hot\")\n",
    "dataset: tf.data.Dataset = tf.data.Dataset.from_generator(lambda: dataset_generator(image_dict, label_lookup), output_signature = output_signature)\n",
    "\n",
    "dataset = dataset.map(lambda x, y: (preprocess_image_bytes(x), y), num_parallel_calls = tf.data.AUTOTUNE, deterministic = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aK2puKOam3xf"
   },
   "outputs": [],
   "source": [
    "def get_dataset_length(image_dict: dict[str, list[bytes]]) -> int:\n",
    "    total_length: int = 0\n",
    "\n",
    "    for value in image_dict.values():\n",
    "        total_length += len(value)\n",
    "\n",
    "    return total_length\n",
    "\n",
    "dataset_count: int = get_dataset_length(image_dict)\n",
    "\n",
    "dataset = dataset.shuffle(dataset_count if dataset_shuffle_buffer_size is None else dataset_shuffle_buffer_size)\n",
    "\n",
    "train_elements: int = int(dataset_count * train_split)\n",
    "train_dataset: tf.data.Dataset = dataset.take(train_elements)\n",
    "val_dataset: tf.data.Dataset = dataset.skip(train_elements)\n",
    "\n",
    "print(f\"Counted {dataset_count} total elements\\nTraining set: {train_elements}\\nValidation set: {dataset_count - train_elements}\")\n",
    "\n",
    "train_dataset = train_dataset.batch(dataset_batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(dataset_batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwDB3cwSaSLt"
   },
   "source": [
    "\n",
    "# Section 2: Model Building\n",
    "\n",
    "## What is Image Classification without an Image Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQcvGwfuzz-5"
   },
   "outputs": [],
   "source": [
    "def init_image_classifier(input_shape: tuple[int, ...], hidden_layers: list[layers.Layer], output_shape: int) -> keras.Sequential:\n",
    "    model: keras.Sequential = keras.Sequential()\n",
    "\n",
    "    model.add(layers.Input(input_shape))\n",
    "\n",
    "    for layer in hidden_layers:\n",
    "        model.add(layer)\n",
    "\n",
    "    model.add(layers.Dense(output_shape, activation = \"softmax\"))\n",
    "    return model\n",
    "\n",
    "try:\n",
    "    assert load_model\n",
    "\n",
    "    model: keras.Sequential = keras.models.load_model(model_path)\n",
    "    \n",
    "    print(f\"Loaded model from {str(model_path)}\")\n",
    "except:\n",
    "    model: keras.Sequential = init_image_classifier((image_size[0], image_size[1], 3), model_init_hidden_layers, len(image_dict_key_list))\n",
    "\n",
    "    model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    print(f\"Compiled new model\")\n",
    "finally:\n",
    "    early_stop_callback: keras.callbacks.EarlyStopping = keras.callbacks.EarlyStopping(\n",
    "        monitor = \"val_loss\",\n",
    "        patience = 3,\n",
    "        restore_best_weights = True,\n",
    "        mode = \"min\"\n",
    "    )\n",
    "\n",
    "    checkpoint_callback: keras.callbacks.ModelCheckpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath = model_path,\n",
    "        monitor = \"val_loss\",\n",
    "        save_best_only = True,\n",
    "        mode = \"min\"\n",
    "    )\n",
    "\n",
    "    model.fit(train_dataset, validation_data = val_dataset,epochs = train_epochs, callbacks = [early_stop_callback, checkpoint_callback], verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNTdO4pTcYFqX2JySokdoMF",
   "mount_file_id": "1ns6x2as7eTq1NhYpFr_BBMQIg3pddl4y",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
